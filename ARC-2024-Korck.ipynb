{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8810484,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<center>\n<img src=\"https://i.postimg.cc/26RtyM0s/3221asdf.jpg\" width=1100>\n</center>","metadata":{"_uuid":"cf2f7c32-eedb-4150-ba46-8eebc9d0ac47","_cell_guid":"70966d68-fb0c-479e-bcf1-8688bc3a6f1e","trusted":true}},{"cell_type":"markdown","source":"\n\n# <div  style=\"color:white; border:lightgreen solid;  font-weight:bold; font-size:120%; text-align:center;padding:12.0px; background:black\">1. OVERVIEW</div>","metadata":{"_uuid":"614678c5-a00d-48b5-922a-3eb86352de45","_cell_guid":"d9464c18-8619-4c87-9e8c-0f5e2cc18851","trusted":true}},{"cell_type":"markdown","source":"# Goal\nThe objective of this competition is to create an algorithm that is capable of solving abstract reasoning tasks. Critically, these are novel tasks: tasks that the algorithm has never seen before. Hence, **simply memorizing** a set of reasoning templates will **not suffice**.\n\nThe goal is to construct the output grid(s) corresponding to the test input grid(s), using 2 trials for each test input.","metadata":{"_uuid":"7bcf6e66-9149-47c4-8246-cc92cda30061","_cell_guid":"5e43269c-762e-432e-917e-0f20feee82d2","trusted":true}},{"cell_type":"markdown","source":"# Data overview","metadata":{"_uuid":"8a44626c-a904-425d-97cb-b25bd69fb6d5","_cell_guid":"cbbe989f-1245-4a14-8c61-dd125202f038","trusted":true}},{"cell_type":"markdown","source":" \n\n\"Constructing the output grid\" involves picking the height and width of the output grid, then filling each cell in the grid with a symbol (integer between 0 and 9, which are visualized as **colors**). **Only exact solutions** (all cells match the expected answer) can be said to be correct.","metadata":{"_uuid":"dc3db96f-0764-4f84-9563-df8e6c7a717c","_cell_guid":"493af46e-91b4-453d-8d8a-b864e9f9368c","trusted":true}},{"cell_type":"markdown","source":"# <div  style=\"color:white; border:lightgreen solid;  font-weight:bold; font-size:120%; text-align:center;padding:12.0px; background:black\">2. DATA LOADING AND PREPARATION</div>","metadata":{"_uuid":"11568205-c890-483c-81a1-71a60f4b4b72","_cell_guid":"c2b926ae-da32-4560-9797-b214977e85ab","trusted":true}},{"cell_type":"markdown","source":"## Import libraries and define parameters","metadata":{"_uuid":"7d941447-a86e-43c5-aa2e-25c8517910f5","_cell_guid":"88aa9fee-ebd6-4c36-a7c6-7dce839a070e","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom   matplotlib import colors\nimport seaborn as sns\n\nimport json\nimport os\nfrom pathlib import Path\n\nfrom subprocess import Popen, PIPE, STDOUT\nfrom glob import glob","metadata":{"_uuid":"4808ed27-9ba0-41fb-9efc-6641ffc9d2ff","_cell_guid":"a3349fb2-1fca-494d-9953-b392a299ae26","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path='/kaggle/input/arc-prize-2024/'\n# Loading JSON data\ndef load_json(file_path):\n    with open(file_path) as f:\n        data = json.load(f)\n    return data","metadata":{"_uuid":"9f1bdeb2-0d22-4ea0-a008-4baaf5455a24","_cell_guid":"2051a6b4-4f29-49ad-b964-384d0a2f7bc5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading files\ntraining_challenges =  load_json(base_path +'arc-agi_training_challenges.json')\ntraining_solutions =   load_json(base_path +'arc-agi_training_solutions.json')\nevaluation_challenges =load_json(base_path +'arc-agi_evaluation_challenges.json')\nevaluation_solutions = load_json(base_path +'arc-agi_evaluation_solutions.json')","metadata":{"_uuid":"07817bc0-e14d-47f2-b1c8-ef779dab9e06","_cell_guid":"5c2d49f6-e0d8-45cd-9ff6-3189b51a1f0f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <div  style=\"color:white; border:lightgreen solid;  font-weight:bold; font-size:120%; text-align:center;padding:12.0px; background:black\">3. DATA EXPLORATION</div>","metadata":{"_uuid":"f4590549-c99d-4c43-b34b-9d12c5bd7062","_cell_guid":"ece97b94-e630-4845-94b6-90944e839391","trusted":true}},{"cell_type":"markdown","source":"All datasets have 400 JSON tasks:","metadata":{"_uuid":"8aa987dc-8f1f-482d-b201-0dda69e15cab","_cell_guid":"a63e3a61-e019-4505-bd9b-4bb5257004f0","trusted":true}},{"cell_type":"code","source":"print(f'Number of training challenges = {len(training_challenges)}')","metadata":{"_uuid":"844a3cf8-0ff6-498c-9d8c-a922d0de6c9b","_cell_guid":"0872eb04-d2ac-4c6e-bd6a-1e377d0e3cdd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of training solutions = {len(training_solutions)}')","metadata":{"_uuid":"4b883a4f-e5d6-46db-945a-2c2fe55169ab","_cell_guid":"d891a090-9408-452b-a0ef-ba002360dff6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of evaluation challenges = {len(evaluation_challenges)}')","metadata":{"_uuid":"e4de44ce-340e-4582-bcd9-1e0b1e4d946c","_cell_guid":"83a07aad-489c-490b-9190-2ed1fc75dedb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of evaluation solutions = {len(evaluation_solutions)}')","metadata":{"_uuid":"1eb712cb-0b24-4dfe-8f26-cb6b57327496","_cell_guid":"4dc675cf-d2f6-4360-b42f-4dd27d4d434c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The names of the first fife \"\"training challenges\" are shown below:","metadata":{"_uuid":"df27dfbd-2c13-48ed-a54a-92ba07077f6a","_cell_guid":"ec508156-c015-4903-8426-2c0c3cd2a44a","trusted":true}},{"cell_type":"code","source":"for i in range(5):\n    t=list(training_challenges)[i]\n    task=training_challenges[t]\n    print(f'Set #{i}, {t}')","metadata":{"_uuid":"95c9d2a1-97b0-4963-b47f-138b358fc4d4","_cell_guid":"11dad383-61a4-45c3-b254-1b3fe55f88b2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In each task, there are **two** dictionary keys, **train** and **test**. We learn the pattern from the train input-output pairs, and then apply the pattern to the test input, to predict an output.","metadata":{"_uuid":"2243f621-231a-4e32-a4af-42340393bef1","_cell_guid":"d3cdb160-b186-4123-a10b-398f4ad5518b","trusted":true}},{"cell_type":"code","source":"task = training_challenges['007bbfb7']\nprint(task.keys())","metadata":{"_uuid":"4759364f-a9d8-4b51-a782-e6fe68778482","_cell_guid":"1a03052f-b07e-45c5-a011-5ee46d88f2cc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tasks have multiple train input-output pairs. Most tasks have a single test input-output pair, although some have more than one.","metadata":{"_uuid":"63790927-2c2b-46de-99e9-2340e74872ee","_cell_guid":"b647ccbe-0708-45d4-893a-90045cc90738","trusted":true}},{"cell_type":"code","source":"n_train_pairs = len(task['train'])\nn_test_pairs = len(task['test'])\n\nprint(f'task contains {n_train_pairs} training pairs')\nprint(f'task contains {n_test_pairs} test pairs')","metadata":{"_uuid":"acce4397-5b54-4139-b786-4dd2bc2a7779","_cell_guid":"37d2b9e6-6838-40cf-86ef-16494deba8f9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dive into the first train input-output pair, we can see the grids are expressed as 2d lists with integers 0-9:","metadata":{"_uuid":"34ec0970-3562-441e-9868-d4fa3e2947fb","_cell_guid":"bbc4ea80-501e-4347-ae10-9c2efec970c8","trusted":true}},{"cell_type":"code","source":"display(task['train'][0]['input'])\ndisplay(task['train'][0]['output'])","metadata":{"_uuid":"f7f2e86d-4323-4896-9291-32f5e843d4bb","_cell_guid":"79d74f7d-de26-427a-bae4-784234cd5c92","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to plot input/output pairs of a task","metadata":{"_uuid":"edbc4954-07a3-4530-9323-75d1c40abfbe","_cell_guid":"8a241ae7-6da6-4919-bb73-dd6bd509df3d","trusted":true}},{"cell_type":"code","source":"# 0:black, 1:blue, 2:red, 3:greed, 4:yellow, # 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\n\n_cmap = colors.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n\nplt.figure(figsize=(4, 1), dpi=200)\nplt.imshow([list(range(10))], cmap=_cmap, norm=norm)\nplt.xticks(list(range(10)))\nplt.yticks([])\nplt.show()","metadata":{"_uuid":"df1160cd-efcf-497a-a7b0-8ae71ac33e4f","_cell_guid":"ea172eca-953a-4a87-b218-105960c713ea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_one(ax, i,train_or_test,input_or_output):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n\n    input_matrix = task[train_or_test][i][input_or_output]\n    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n    \n    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.set_title(train_or_test + ' '+input_or_output)\n    \n\ndef plot_task(task):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"    \n    num_train = len(task['train'])\n    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n    for i in range(num_train):     \n        plot_one(axs[0,i],i,'train','input')\n        plot_one(axs[1,i],i,'train','output')        \n    plt.tight_layout()\n    plt.show()        \n        \n#     num_test = len(task['test'])\n#     fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n#     if num_test==1: \n#         plot_one(axs[0],0,'test','input')\n#         plot_one(axs[1],0,'test','output')     \n#     else:\n#         for i in range(num_test):      \n#             plot_one(axs[0,i],i,'test','input')\n#             plot_one(axs[1,i],i,'test','output')  \n#     plt.tight_layout()\n#     plt.show()","metadata":{"_uuid":"fbfd7d31-8660-4843-9edb-8b4b1b186f69","_cell_guid":"4e886125-8fb6-4242-a24d-9a5a6ae6fd28","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization Training set","metadata":{"_uuid":"51ec1a2b-4d27-484f-8bc0-77a2819908d9","_cell_guid":"75c2a967-e55e-440c-8120-1363a43a4023","trusted":true}},{"cell_type":"code","source":"for i in range(5):\n    t=list(training_challenges)[i]\n    task=training_challenges[t]\n    print(f'Set #{i}, {t}')\n    plot_task(task)","metadata":{"_uuid":"8598cf30-b3e0-45cd-ade3-253e54ec6606","_cell_guid":"6abacb10-37f6-480d-87b0-1e956648ed82","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization Evaluating set","metadata":{"_uuid":"295c3e27-4a1b-46f6-ad85-788383d206be","_cell_guid":"ee0ece5a-bc1f-47c7-8683-9a6d3a0d36c6","trusted":true}},{"cell_type":"code","source":"for i in range(5):\n    t=list(evaluation_challenges)[i]\n    task=evaluation_challenges[t]\n    print(f'Set #{i}, {t}')\n    plot_task(task)","metadata":{"_uuid":"312c84ef-7444-40c0-a300-c7f367630fb7","_cell_guid":"de295c96-acf0-4ad5-aff3-5a6459573479","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# <div  style=\"color:white; border:lightgreen solid;  font-weight:bold; font-size:120%; text-align:center;padding:12.0px; background:black\">4. MODELLING</div>","metadata":{"_uuid":"50411be1-aa40-48df-ad4b-017e1330b4f4","_cell_guid":"2307ecff-0115-4883-b51f-e1562f81a3c2","trusted":true}},{"cell_type":"code","source":"import numpy as np\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom typing import Literal\n\ndef create_rgb_array(input_output_matrix):\n#     print(\"Matrix:\")\n#     print(input_output_matrix)\n    \n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n\n    normed_matrix = norm(input_output_matrix)\n    rgb_array = cmap(normed_matrix)\n    rgb_array = rgb_array[..., :3]\n    \n#     print(\"RGB Array (Normalized):\")\n#     print(rgb_array)\n    \n    return rgb_array\n\ndef get_rgb_task(task, kind:Literal['train', 'test']='train'):\n    num_train = len(task[kind])\n    train_input_rgb = []\n    train_output_rgb = []\n    \n    for i in range(num_train):\n        input_matrix = task[kind][i]['input']\n        output_matrix = task[kind][i]['output']\n        \n        train_input_rgb.append(create_rgb_array(input_matrix))\n        train_output_rgb.append(create_rgb_array(output_matrix))\n        \n    return train_input_rgb, train_output_rgb\n\ndef display_with_matplotlib(rgb_array):\n    plt.imshow(rgb_array)\n    plt.axis('off')\n    plt.show()\n\nt = list(training_challenges)[0]\ntask = training_challenges[t]\nprint(f'Set #{0}, {t}')\n# plot_task(task)\ntrain_input_rgb, train_output_rgb = get_rgb_task(task, 'train')\ndisplay_with_matplotlib(train_input_rgb[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport bisect\nfrom typing import List, Tuple, Literal\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nfrom PIL import Image\nimport matplotlib.colors as colors\nimport pickle\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pickle\nimport numpy as np\nimport matplotlib.colors as colors\nfrom typing import Literal\n\n# Constants for maximum grid dimensions\nMAX_ROWS, MAX_COLS = 30, 30\n\n# Pad the array to the given dimensions\ndef pad_array(array, max_rows=MAX_ROWS, max_cols=MAX_COLS, padding_value=-1.0):\n    padded_array = np.full((max_rows, max_cols), padding_value)\n    rows, cols = len(array), len(array[0])\n    start_row = (max_rows - rows) // 2\n    start_col = (max_cols - cols) // 2\n    padded_array[start_row:start_row+rows, start_col:start_col+cols] = array\n    return padded_array\n\n# Convert the padded array to RGB\ndef create_rgb_array(input_matrix):\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    normed_matrix = norm(input_matrix)\n    rgb_array = cmap(normed_matrix)\n    rgb_array = rgb_array[..., :3]\n    return rgb_array\n\n# Get padded RGB arrays for the task\ndef get_padded_rgb_task(task, kind: Literal['train', 'test'] = 'train'):\n    input_rgb, output_rgb = [], []\n    for pair in task[kind]:\n        input_matrix = pad_array(pair['input'])\n        input_rgb.append(create_rgb_array(input_matrix))\n        if 'output' in pair:\n            output_matrix = pad_array(pair['output'])\n            output_rgb.append(create_rgb_array(output_matrix))\n        else:\n            output_rgb.append(None)\n    return input_rgb, output_rgb\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process and save the dataset with size information\ndef save_dataset_with_sizes(training_challenges, filename):\n    dataset = {\n        'train_input_rgb': [],\n        'train_output_rgb': [],\n        'test_input_rgb': [],\n        'train_input_sizes': [],\n        'train_output_sizes': [],\n        'test_input_sizes': [],\n        'labels': []\n    }\n\n    for i in range(len(training_challenges)):\n        t = list(training_challenges)[i]\n        task = training_challenges[t]\n        print(f'Processing Set #{i}, {t}', end='\\r')\n        \n        # Process training pairs\n        train_input_rgb, train_output_rgb = get_padded_rgb_task(task, 'train')\n        for j in range(len(task['train'])):\n            input_matrix = task['train'][j]['input']\n            output_matrix = task['train'][j]['output']\n            dataset['train_input_rgb'].append(train_input_rgb[j])\n            dataset['train_output_rgb'].append(train_output_rgb[j])\n            dataset['train_input_sizes'].append((len(input_matrix), len(input_matrix[0])))\n            dataset['train_output_sizes'].append((len(output_matrix), len(output_matrix[0])))\n            dataset['labels'].append(t)\n        \n        # Process test pairs (only inputs)\n        test_input_rgb, _ = get_padded_rgb_task(task, 'test')\n        for k in range(len(task['test'])):\n            input_matrix = task['test'][k]['input']\n            dataset['test_input_rgb'].append(test_input_rgb[k])\n            dataset['test_input_sizes'].append((len(input_matrix), len(input_matrix[0])))\n\n    # Debug: Verify dataset content\n    print(f\"\\nTotal valid train samples: {len(dataset['train_input_rgb'])}\")\n    print(f\"Total valid test samples: {len(dataset['test_input_rgb'])}\")\n\n    # Save the dataset to a file using pickle\n    with open(filename, 'wb') as f:\n        pickle.dump(dataset, f)\n\n    print(f'\\nDataset saved to {filename}')\n\n# Example usage\nsave_dataset_with_sizes(training_challenges, 'processed_dataset_with_sizes.pkl')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pickle\n\n# Function to flatten RGB arrays with size information\ndef flatten_rgb_arrays_with_sizes(rgb_arrays, sizes):\n    flattened_arrays = []\n    for rgb_array, size in zip(rgb_arrays, sizes):\n        flattened_array = rgb_array.flatten()\n        flattened_arrays.append(np.concatenate((flattened_array, np.array(size))))\n    return np.array(flattened_arrays)\n\n# Function to reshape predictions back to 2D\ndef reshape_predictions(predictions, sizes):\n    reshaped_predictions = []\n    num_features = predictions.shape[1] - 2  # excluding size information\n    for i, size in enumerate(sizes):\n        height, width = size\n        reshaped_prediction = predictions[i][:num_features].reshape(height, width, 3)\n        reshaped_predictions.append(reshaped_prediction)\n    return reshaped_predictions\n\n# Function to calculate accuracy\ndef calculate_accuracy(predictions, ground_truth):\n    correct = 0\n    for pred, gt in zip(predictions, ground_truth):\n        if np.array_equal(pred, gt):\n            correct += 1\n    accuracy = correct / len(ground_truth)\n    return accuracy\n\n# Load the dataset with size information\ndef load_dataset_with_sizes(filename):\n    with open(filename, 'rb') as f:\n        dataset = pickle.load(f)\n    return dataset\n\n# Example usage\ndataset = load_dataset_with_sizes('processed_dataset_with_sizes.pkl')\ntrain_input_rgb = dataset['train_input_rgb']\ntrain_output_rgb = dataset['train_output_rgb']\ntest_input_rgb = dataset['test_input_rgb']\ntrain_input_sizes = dataset['train_input_sizes']\ntrain_output_sizes = dataset['train_output_sizes']\ntest_input_sizes = dataset['test_input_sizes']\nlabels = dataset['labels']\n\n# # Flatten the train data for validation\n# train_input_rgb_flat = flatten_rgb_arrays_with_sizes(train_input_rgb, train_input_sizes)\n# train_output_rgb_flat = flatten_rgb_arrays_with_sizes(train_output_rgb, train_output_sizes)\n\n# X_train = torch.FloatTensor(train_input_rgb_flat)\n# y_train = torch.FloatTensor(train_output_rgb_flat)\n\n# # Debug: Print shapes\n# print(f\"X_train shape: {X_train.shape}\")\n# print(f\"y_train shape: {y_train.shape}\")\n\n# # Make predictions with the trained model for validation\n# with torch.no_grad():\n#     outputs = trained_model(X_train)\n\n# # Debug: Print shapes after prediction\n# print(f\"Outputs shape after prediction: {outputs.shape}\")\n\n# # Reshape the predictions\n# reshaped_predictions = reshape_predictions(outputs.numpy(), train_output_sizes)\n# reshaped_ground_truth = reshape_predictions(y_train.numpy(), train_output_sizes)\n\n# # Debug: Print lengths after reshaping\n# print(f\"Reshaped predictions length: {len(reshaped_predictions)}\")\n# print(f\"Reshaped ground truth length: {len(reshaped_ground_truth)}\")\n\n# # Calculate accuracy\n# accuracy = calculate_accuracy(reshaped_predictions, reshaped_ground_truth)\n# print(f'Accuracy: {accuracy:.4f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# # Load the dataset with size information\n# def load_dataset_with_sizes(filename):\n#     with open(filename, 'rb') as f:\n#         dataset = pickle.load(f)\n#     return dataset\n\n# # Example usage\n# dataset = load_dataset_with_sizes('processed_dataset_with_sizes.pkl')\n# train_input_rgb = dataset['train_input_rgb']\n# train_output_rgb = dataset['train_output_rgb']\n# test_input_rgb = dataset['test_input_rgb']\n# train_input_sizes = dataset['train_input_sizes']\n# train_output_sizes = dataset['train_output_sizes']\n# test_input_sizes = dataset['test_input_sizes']\n# labels = dataset['labels']\n\n# Display the first example of train set\ndisplay_with_matplotlib(train_input_rgb[0])\n\n# If you want to display the first example of the test set (if it exists)\nif test_input_rgb and test_input_rgb[0] is not None:\n    display_with_matplotlib(test_input_rgb[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport os\n\n# Choose the device based on availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass SplineActivation(nn.Module):\n    def __init__(self, num_knots=10, degree=3):\n        super(SplineActivation, self).__init__()\n        self.num_knots = num_knots\n        self.degree = degree\n        self.x = nn.Parameter(torch.linspace(-1.0, 1.0, num_knots), requires_grad=False)\n\n        # Allow y to be updated during training\n        self.y = nn.Parameter(torch.sin(self.x * 3.14159) + 0.1 * torch.randn(self.num_knots), requires_grad=True)\n\n        # Initial computation of coefficients, just for initial debugging\n        _, self.coefficients = self.compute_spline(self.x, self.y)\n\n        self.w = nn.Parameter(torch.tensor(1.0))  # Initialize weight\n        self.basis_function = nn.SiLU()  # Using SiLU (Swish) as basis function\n\n    def compute_spline(self, x, y):\n        if x.size(0) < 3:\n            raise ValueError('Too short an array')\n        if x.size(0) != y.size(0):\n            raise ValueError('Array lengths are different')\n\n        h = x[1:] - x[:-1]\n        if torch.any(h <= 0):\n            raise ValueError('X must be strictly increasing')\n\n        n = x.size(0)\n        A, B, C = self.create_tridiagonal_matrix(n, h)\n        D = self.create_target(n, h, y)\n        M = self.solve_tridiagonal_system(A, B, C, D)\n\n        coefficients = torch.stack([\n            (M[1:] - M[:-1]) * h**2 / 6,\n            M[:-1] * h**2 / 2,\n            (y[1:] - y[:-1] - (M[1:] + 2 * M[:-1]) * h**2 / 6),\n            y[:-1]\n        ], dim=1)\n\n        return self.spline_function(x, coefficients), coefficients\n\n    def create_tridiagonal_matrix(self, n, h):\n        A = torch.cat((h[:-1] / (h[:-1] + h[1:]), torch.tensor([0.0], device=h.device)))\n        B = torch.full((n,), 2.0, device=h.device)\n        C = torch.cat((torch.tensor([0.0], device=h.device), h[1:] / (h[:-1] + h[1:])))\n        return A, B, C\n\n    def create_target(self, n, h, y):\n        diff_quotients = 6 * ((y[2:] - y[1:-1]) / h[1:] - (y[1:-1] - y[:-2]) / h[:-1]) / (h[:-1] + h[1:])\n        return torch.cat((torch.tensor([0.0], device=h.device), diff_quotients, torch.tensor([0.0], device=h.device)))\n\n    def solve_tridiagonal_system(self, A, B, C, D):\n        n = B.size(0)\n        c_p = torch.zeros(n, device=B.device)\n        d_p = torch.zeros(n, device=B.device)\n        X = torch.zeros(n, device=B.device)\n\n        c_p[0] = C[0] / B[0]\n        d_p[0] = D[0] / B[0]\n        for i in range(1, n-1):\n            denom = B[i] - A[i-1] * c_p[i-1]\n            c_p[i] = C[i] / denom\n            d_p[i] = (D[i] - A[i-1] * d_p[i-1]) / denom\n\n        X[-1] = d_p[-1]\n        for i in range(n-2, -1, -1):\n            X[i] = d_p[i] - c_p[i] * X[i+1]\n\n        return X\n\n    def spline_function(self, x, coefficients):\n        def spline(val):\n            idx = min(bisect.bisect(x.cpu().numpy(), val) - 1, x.size(0) - 2)\n            z = (val - x[idx].item()) / (x[idx+1].item() - x[idx].item())\n            C = coefficients[idx]\n            return (((C[0] * z + C[1]) * z + C[2]) * z + C[3]).item()\n        return spline\n\n    def forward(self, x):\n        x_clipped = torch.clamp(x, -1, 1)\n\n        _, coefficients = self.compute_spline(self.x, self.y)\n\n        indices = torch.searchsorted(self.x, x_clipped.detach(), right=True) - 1\n        indices = torch.clamp(indices, 0, self.num_knots - 2)\n        idx_x = self.x[indices]\n        idx_x1 = self.x[indices + 1]\n        h = idx_x1 - idx_x\n        z = (x_clipped - idx_x) / h\n        C = coefficients[indices]\n\n        z = z.unsqueeze(-1)\n        C = C.unsqueeze(2)\n        y_clipped = (((C[..., 0] * z + C[..., 1]) * z + C[..., 2]) * z + C[..., 3])\n\n        return self.w * (self.basis_function(x) + y_clipped.squeeze(-1))\n\nclass KAN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, kernel_type='spline', num_knots=10):\n        super(KAN, self).__init__()\n        self.phi1 = nn.Linear(input_dim, hidden_dim)\n        self.psi1 = nn.Linear(input_dim, hidden_dim)\n        self.phi2 = nn.Linear(hidden_dim, hidden_dim)\n        self.psi2 = nn.Linear(hidden_dim, hidden_dim)\n        self.phi3 = nn.Linear(hidden_dim, output_dim)\n        self.psi3 = nn.Linear(hidden_dim, output_dim)\n        self._he_init()\n\n        if kernel_type == 'spline':\n            self.spline1 = SplineActivation(num_knots)\n            self.spline2 = SplineActivation(num_knots)\n            self.spline3 = SplineActivation(num_knots)\n            self.spline4 = SplineActivation(num_knots)\n            self.spline5 = SplineActivation(num_knots)\n            self.spline6 = SplineActivation(num_knots)\n\n    # He initialization function\n    def _he_init(self):\n        for layer in [self.phi1, self.psi1, self.phi2, self.psi2, self.phi3, self.psi3]:\n            nn.init.kaiming_normal_(layer.weight)\n            if layer.bias is not None:\n                nn.init.constant_(layer.bias, 0)\n\n    def forward(self, x):\n        def apply_activation(act, x):\n            return act(x)\n\n        x1 = apply_activation(self.spline1, self.phi1(x))\n        x2 = apply_activation(self.spline2, self.psi1(x))\n        sum_x = x1 + x2\n        x3 = apply_activation(self.spline3, self.phi2(sum_x))\n        x4 = apply_activation(self.spline4, self.psi2(sum_x))\n        sum_x2 = x3 + x4\n        x5 = apply_activation(self.spline5, self.phi3(sum_x2))\n        x6 = apply_activation(self.spline6, self.psi3(sum_x2))\n        output = x5 + x6\n        return torch.sigmoid(output)\n    \ndef train_model(model, X_train, y_train, epochs=2000, learning_rate=0.01, save_step=100, save_path=\"model_checkpoints\", device='cpu'):\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    loss_list = []\n\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n\n    model.to(device)\n    X_train = X_train.to(device)\n    y_train = y_train.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n        outputs = model(X_train)\n        loss = criterion(outputs, y_train)\n        loss.backward()\n        optimizer.step()\n\n        loss_list.append(loss.item())\n        if (epoch + 1) % save_step == 0:\n            torch.save(model.state_dict(), os.path.join(save_path, f\"model_epoch_{epoch + 1}.pth\"))\n            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}, Model saved.\")\n\n    print(f\"Training complete! Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n    return model, loss_list    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage for GPU\n# Flatten the train data\ntrain_input_rgb_flat = flatten_rgb_arrays_with_sizes(train_input_rgb, train_input_sizes)\ntrain_output_rgb_flat = flatten_rgb_arrays_with_sizes(train_output_rgb, train_output_sizes)\n\nX_train = torch.FloatTensor(train_input_rgb_flat)\ny_train = torch.FloatTensor(train_output_rgb_flat)\n\ninput_dim = X_train.shape[1]\nhidden_dim = input_dim + y_train.shape[1]\noutput_dim = y_train.shape[1]\nnum_knots = 3\nepochs = 200\nlearning_rate = 0.01\nsave_step = 10\nsave_path = \"k3_model_checkpoints\"\n\nkan_model = KAN(input_dim, hidden_dim, output_dim, kernel_type='spline', num_knots=num_knots)\ntrained_model, loss_list = train_model(kan_model, X_train, y_train, epochs=epochs, learning_rate=learning_rate, save_step=save_step, save_path=save_path, device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T03:35:35.554620Z","iopub.execute_input":"2024-06-18T03:35:35.555270Z","iopub.status.idle":"2024-06-18T03:57:59.978934Z","shell.execute_reply.started":"2024-06-18T03:35:35.555235Z","shell.execute_reply":"2024-06-18T03:57:59.977980Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch [10/200], Loss: 0.2855, Model saved.\nEpoch [20/200], Loss: 0.2409, Model saved.\nEpoch [30/200], Loss: 0.1965, Model saved.\nEpoch [40/200], Loss: 0.1587, Model saved.\nEpoch [50/200], Loss: 0.1317, Model saved.\nEpoch [60/200], Loss: 0.1152, Model saved.\nEpoch [70/200], Loss: 0.1060, Model saved.\nEpoch [80/200], Loss: 0.1010, Model saved.\nEpoch [90/200], Loss: 0.0982, Model saved.\nEpoch [100/200], Loss: 0.0966, Model saved.\nEpoch [110/200], Loss: 0.0955, Model saved.\nEpoch [120/200], Loss: 0.0948, Model saved.\nEpoch [130/200], Loss: 0.0943, Model saved.\nEpoch [140/200], Loss: 0.0940, Model saved.\nEpoch [150/200], Loss: 0.0937, Model saved.\nEpoch [160/200], Loss: 0.0935, Model saved.\nEpoch [170/200], Loss: 0.0933, Model saved.\nEpoch [180/200], Loss: 0.0932, Model saved.\nEpoch [190/200], Loss: 0.0931, Model saved.\nEpoch [200/200], Loss: 0.0930, Model saved.\nTraining complete! Epoch [200/200], Loss: 0.0930\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage for TPU\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\ndef _mp_fn(rank, flags):\n    device = xm.xla_device()\n    # Flatten the train data\n    train_input_rgb_flat = flatten_rgb_arrays_with_sizes(train_input_rgb, train_input_sizes)\n    train_output_rgb_flat = flatten_rgb_arrays_with_sizes(train_output_rgb, train_output_sizes)\n\n    X_train = torch.FloatTensor(train_input_rgb_flat)\n    y_train = torch.FloatTensor(train_output_rgb_flat)\n\n    input_dim = X_train.shape[1]\n    output_dim = y_train.shape[1]\n    hidden_dim = (input_dim + output_dim)//2\n    num_knots = 5\n    epochs = 200\n    learning_rate = 0.01\n    save_step = 10\n    save_path = \"tk5_model_checkpoints\"\n\n    kan_model = KAN(input_dim, hidden_dim, output_dim, kernel_type='spline', num_knots=num_knots)\n    trained_model, loss_list = train_model(kan_model, X_train, y_train, epochs=epochs, learning_rate=learning_rate, save_step=save_step, save_path=save_path, device=device)\n\nif __name__ == '__main__':\n    FLAGS = {}\n    xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Function to reshape predictions back to 2D\ndef reshape_predictions(predictions, sizes):\n    reshaped_predictions = []\n    num_features = predictions.shape[1] - 2  # excluding size information\n    for i, size in enumerate(sizes):\n        height, width = size\n        reshaped_prediction = predictions[i][:num_features].reshape(height, width, 3)\n        reshaped_predictions.append(reshaped_prediction)\n    return reshaped_predictions\n\n# Function to calculate accuracy\ndef calculate_accuracy(predictions, ground_truth):\n    correct = 0\n    for pred, gt in zip(predictions, ground_truth):\n        if np.array_equal(pred, gt):\n            correct += 1\n    accuracy = correct / len(ground_truth)\n    return accuracy\n\n# Function to load and evaluate the model\ndef evaluate_model(model, X_test, y_test, test_output_sizes, device='cpu'):\n    model.to(device)\n    X_test = X_test.to(device)\n    y_test = y_test.to(device)\n\n    with torch.no_grad():\n        outputs = model(X_test)\n    \n    reshaped_predictions = reshape_predictions(outputs.cpu().numpy(), test_output_sizes)\n    reshaped_ground_truth = reshape_predictions(y_test.cpu().numpy(), test_output_sizes)\n\n    accuracy = calculate_accuracy(reshaped_predictions, reshaped_ground_truth)\n    print(f'Accuracy: {accuracy:.4f}')\n    return accuracy\n\n# Example usage for evaluation\ndataset = load_dataset_with_sizes('processed_dataset_with_sizes.pkl')\ntest_input_rgb = dataset['test_input_rgb']\ntest_output_rgb = dataset['test_output_rgb']\ntest_input_sizes = dataset['test_input_sizes']\ntest_output_sizes = dataset['test_output_sizes']\n\ntest_input_rgb_flat = flatten_rgb_arrays_with_sizes(test_input_rgb, test_input_sizes)\ntest_output_rgb_flat = flatten_rgb_arrays_with_sizes(test_output_rgb, test_output_sizes)\n\nX_test = torch.FloatTensor(test_input_rgb_flat)\ny_test = torch.FloatTensor(test_output_rgb_flat)\n\n# Load the trained model\ntrained_model = KAN(input_dim, hidden_dim, output_dim, kernel_type='spline', num_knots=num_knots)\ntrained_model.load_state_dict(torch.load('model_checkpoints/model_epoch_2000.pth'))\n\n# Evaluate the model\nevaluate_model(trained_model, X_test, y_test, test_output_sizes, device=device)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-18T03:05:09.539798Z","iopub.execute_input":"2024-06-18T03:05:09.540323Z","iopub.status.idle":"2024-06-18T03:05:09.547564Z","shell.execute_reply.started":"2024-06-18T03:05:09.540286Z","shell.execute_reply":"2024-06-18T03:05:09.545794Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def resume_training(model, optimizer, X_train, y_train, start_epoch, end_epoch=2000, learning_rate=0.01, save_step=100, save_path=\"model_checkpoints\", device='cpu'):\n    criterion = nn.MSELoss()\n    loss_list = []\n\n    model.to(device)\n    X_train = X_train.to(device)\n    y_train = y_train.to(device)\n\n    for epoch in range(start_epoch, end_epoch):\n        model.train()\n        optimizer.zero_grad()\n        outputs = model(X_train)\n        loss = criterion(outputs, y_train)\n        loss.backward()\n        optimizer.step()\n\n        loss_list.append(loss.item())\n        if (epoch + 1) % save_step == 0:\n            torch.save(model.state_dict(), os.path.join(save_path, f\"model_epoch_{epoch + 1}.pth\"))\n            torch.save(optimizer.state_dict(), os.path.join(save_path, f\"optimizer_epoch_{epoch + 1}.pth\"))\n            print(f\"Epoch [{epoch + 1}/{end_epoch}], Loss: {loss.item():.4f}, Model saved.\")\n\n    print(f\"Training complete! Epoch [{end_epoch}], Loss: {loss.item():.4f}\")\n    return model, loss_list\n\n# Example usage for resuming training\ntrained_model = KAN(input_dim, hidden_dim, output_dim, kernel_type='spline', num_knots=num_knots)\ntrained_model.load_state_dict(torch.load('model_checkpoints/model_epoch_1000.pth'))\n\noptimizer = optim.Adam(trained_model.parameters(), lr=learning_rate)\noptimizer.load_state_dict(torch.load('model_checkpoints/optimizer_epoch_1000.pth'))\n\nstart_epoch = 1000\nend_epoch = 3000  # Continue training for 2000 more epochs\n\ntrained_model, loss_list = resume_training(trained_model, optimizer, X_train, y_train, start_epoch, end_epoch, learning_rate, save_step, save_path, device=device)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(trained_model, 'kan_model.pth')\nprint('Model saved to kan_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T04:00:39.457765Z","iopub.execute_input":"2024-06-18T04:00:39.458621Z","iopub.status.idle":"2024-06-18T04:00:40.396878Z","shell.execute_reply.started":"2024-06-18T04:00:39.458587Z","shell.execute_reply":"2024-06-18T04:00:40.395805Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model saved to kan_model.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the entire model\nloaded_model = torch.load('kan_model.pth')\nloaded_model.eval()  # Set the model to evaluation mode\nprint('Model loaded from kan_model.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T04:00:46.742200Z","iopub.execute_input":"2024-06-18T04:00:46.742544Z","iopub.status.idle":"2024-06-18T04:00:47.130455Z","shell.execute_reply.started":"2024-06-18T04:00:46.742513Z","shell.execute_reply":"2024-06-18T04:00:47.129390Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Model loaded from kan_model.pth\n","output_type":"stream"}]}]}